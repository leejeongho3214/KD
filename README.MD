# Knowledge Distillation via Assistant 

This is the implementation of above paper submitted in IEEE Tensymp 2021

## Contents
### KD via Assistant
- 조수모델을 통해 일방적인 지식전이에서의 용량차이로 발생하는 문제점을 최소화시켜줌으로써 선생모델만 사용한 방법보다 조수모델을 덧붙인 방법이 더 좋은 성능을 보여줌.




